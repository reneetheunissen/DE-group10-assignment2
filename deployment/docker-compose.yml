version: '3.8'

# Specify the volumes
volumes:
  # Get the data to use for Spark
  spark-data:
    driver_opts:
      type: none
      device: /home/r_h_theunissen/DE-group10-assignment2/data
      o: bind
  # Get the notebooks
  notebooks:
    driver_opts:
      type: none
      device: /home/r_h_theunissen/DE-group10-assignment2/notebooks
      o: bind

# Specify the services
services:
  # The Spark driver application
  spark-driver-app:
    # Specify what to build
    build: jupyter-all-spark-notebook-gcp
    # Specify the container name
    container_name: spark-driver-app
    # Specify the user
    user: root
    # Ports to use
    ports:
      - "8888:8888"
      - "4040:4040"
    # Specify the environment requirements
    environment:
      - JUPYTER_ENABLE_LAB=yes
    # Volumes to use
    volumes:
    # Jovyan is the default user and should not be changed
      - notebooks:/home/jovyan/notebooks
      - spark-data:/home/jovyan/data

  # The Spark master
  spark-master:
    # Specify what to build
    build: ./spark-bitnami-python3.9
    # Specify the container name
    container_name: spark-master
    # Specify the user
    user: root
    # Specify the environment variables
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_DAEMON_MEMORY=2G
      - SPARK_MASTER_OPTS="-Dspark.deploy.defaultCores=1"
    # Specify the ports to use
    ports:
      - "8080:8080"
      - "7077:7077"
    # Specify the volumes to use
    volumes:
      - spark-data:/home/jovyan/data

  # First Spark worker
  spark-worker-1:
    # Specify what to build
    build: ./spark-bitnami-python3.9
    # Specify the container name
    container_name: spark-worker-1
    # Specify the user
    user: root
    # Specify what the worker depends on
    depends_on:
      - spark-master
    # Specify the environment requirements
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    # Specify the ports to use
    ports:
      - "8081:8081"
    # Specify the volumes to use
    volumes:
      - spark-data:/home/jovyan/data

  # Second Spark worker
  spark-worker-2:
    # Specify what to build
    build: ./spark-bitnami-python3.9
    # Specify the container name
    container_name: spark-worker-2
    # Specify the user
    user: root
    # Specify what the worker depends on
    depends_on:
      - spark-master
    # Specify the environment requirements
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    # Specify the ports to use
    ports:
      - "8082:8081"
    # Specify the volumes to use
    volumes:
      - spark-data:/home/jovyan/data